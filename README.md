<div align="center">

# ğŸŒŠ FlexAligner
### Robust Speech-Text Alignment from Signal to Symbol

[![Laboratory](https://img.shields.io/badge/Laboratory-USTC_Phonetics-red.svg)](http://phonetics.ustc.edu.cn/)
[![Python](https://img.shields.io/badge/Python-3.9%2B-blue.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Model](https://img.shields.io/badge/Model-Wav2Vec2.0-orange.svg)](https://huggingface.co/USTCPhonetics)

**A Neural-Based Forced Alignment Framework for "Wild" Real-World Data**
<br>
**é¢å‘çœŸå®éå—æ§æ•°æ®çš„æ·±åº¦å­¦ä¹ å¼ºé²æ£’æ€§å¯¹é½å·¥å…·**

[**English**](#-introduction) | [**ç®€ä½“ä¸­æ–‡**](#-ç®€ä»‹)

</div>

---

## ğŸ“– Introduction

**FlexAligner** is a robust speech-text alignment framework built upon **wav2vec 2.0**. It is developed to address the complexities of real-world linguistic data, where audio signals and textual transcriptions often exhibit discrepancies.

In spontaneous speech or field recordings, issues such as **background noise, laughter, hesitations (insertions)**, and **transcription omissions (deletions)** pose challenges for alignment accuracy. FlexAligner addresses these by decomposing the problem into two stages:

1.  **Macro-Segmentation (CTC Chunking):** Utilizes the CTC loss mechanism to identify reliable speech segments while tolerating unannotated acoustic events.
2.  **Micro-Alignment (Local Alignment):** Performs frame-level boundary regression within matched segments using a dynamic time-calibration algorithm.

### ğŸŒŸ Key Features

* **ğŸ›¡ï¸ Tolerance to Mismatch:** FlexAligner is capable of handling imperfect alignments between audio and text. It leverages CTC to detect and treat non-speech segments (e.g., laughter, noise) as `<NULL>` tokens, reducing the risk of forced misalignment.
* **ğŸ§¹ Integrated Text Normalization:** Includes a lightweight frontend for automatic punctuation removal, case normalization, and OOV (Out-Of-Vocabulary) phoneme mapping.
* **ğŸŒ Multi-Lingual Support:** Pre-trained models available for **Mandarin Chinese** and **English**, with an architecture designed for extensibility.

---

## ğŸŒ ç®€ä»‹

**FlexAligner** æ˜¯ä¸€ä¸ªåŸºäº **wav2vec 2.0** çš„è¯­éŸ³-æ–‡æœ¬å¯¹é½æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³çœŸå®ä¸–ç•Œæ•°æ®ï¼ˆWild Dataï¼‰ä¸­å¸¸è§çš„éç†æƒ³å¯¹é½é—®é¢˜ã€‚

åœ¨è‡ªç„¶è¯­è¨€ç ”ç©¶ä¸­ï¼Œå½•éŸ³ä¸æ–‡æœ¬å¾€å¾€éš¾ä»¥ä¸¥æ ¼å¯¹åº”ã€‚é¢å¯¹**å™ªéŸ³ã€ç¬‘å£°ã€è¯­æ°”è¯æ’å…¥**æˆ–**æ–‡æœ¬æ¼è®°**ï¼Œä¼ ç»Ÿçš„å¼ºåˆ¶å¯¹é½ç®—æ³•å¯èƒ½ä¼šå—åˆ°å¹²æ‰°ã€‚FlexAligner é€šè¿‡â€œåˆ†æ²»ç­–ç•¥â€åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼š

1.  **å®è§‚åˆ‡åˆ† (Chunking):** åˆ©ç”¨ CTC æœºåˆ¶è¿‡æ»¤éè¨€è¯­å£°éŸ³ï¼Œåœ¨éå—æ§æ•°æ®ä¸­å¯»æ‰¾å¯é çš„â€œå¯¹é½é”šç‚¹â€ã€‚
2.  **å¾®è§‚å¯¹é½ (Alignment):** åœ¨é”šç‚¹å†…éƒ¨è¿›è¡ŒåŸºäºç‰©ç†é‡‡æ ·ç‚¹çš„é«˜ç²¾åº¦è¾¹ç•Œå›å½’ã€‚

### æ ¸å¿ƒä¼˜åŠ¿

* **ğŸ›¡ï¸ é²æ£’æ€§è®¾è®¡ï¼š** èƒ½å¤Ÿå®¹å¿éŸ³é¢‘ä¸æ–‡æœ¬çš„ä¸€å®šç¨‹åº¦ä¸ä¸€è‡´ã€‚å¯¹äºæœªè½¬å†™çš„ç¬‘å£°æˆ–å™ªéŸ³ï¼Œç³»ç»Ÿå°†å…¶æ ‡è®°ä¸º `<NULL>`ï¼Œè€Œéå¼ºåˆ¶åŒ¹é…åˆ°é‚»è¿‘éŸ³ç´ ã€‚
* **ğŸ§¹ è‡ªåŠ¨åŒ–å‰ç«¯ï¼š** å†…ç½®æ–‡æœ¬å½’ä¸€åŒ–æ¨¡å—ï¼Œè‡ªåŠ¨å¤„ç†æ ‡ç‚¹å»é™¤ã€å¤§å°å†™è½¬æ¢åŠç”Ÿåƒ»è¯ï¼ˆOOVï¼‰çš„æ¨¡ç³ŠåŒ¹é…ã€‚
* **ğŸŒ å¤šè¯­è¨€æ”¯æŒï¼š** ç›®å‰å·²æ”¯æŒ **æ™®é€šè¯ (Mandarin)** ä¸ **è‹±è¯­ (English)**ã€‚

---

## ğŸ—ï¸ Architecture

```mermaid
graph TD
    Input[Input: Raw Audio + Raw Text] --> Frontend(Text Normalization & G2P);
    Frontend --> B(Stage 1: CTC Chunking);
    B -->|Filter Noise/Mismatch| C{Reliable Islands};
    C -->|Matched Segments| D(Stage 2: Local Alignment);
    D -->|Viterbi Decoding| E[Fine-grained Boundaries];
    E -->|Dynamic Calibration| F[Final TextGrid];
```

ğŸš€ Installation
```Bash

# Clone the repository
git clone [https://github.com/USTCPhonetics/FlexAligner.git](https://github.com/USTCPhonetics/FlexAligner.git)
cd FlexAligner

# Install in editable mode with all dependencies (Recommended)
# This includes tools for testing, robustness, and security checks.
pip install -e ".[all]"
```

ğŸ’» Usage
FlexAligner provides a smart unified interface. You can pass a single audio file or a batch list, and it will automatically route the task.

1. Command Line Interface (CLI)
Mode A: Single File Alignment Ideal for quick tests or individual recordings.

```Bash

# Basic usage (Auto-detects transcript from audio filename)
flexaligner demo.wav

# Specify transcript and output explicitly
flexaligner audio.wav transcript.txt -o result.TextGrid

# Force language (triggers Language Lock) and device
flexaligner en.wav en.txt -l en --device cuda
```

Mode B: High-Throughput Batch Processing Ideal for processing large-scale corpora (e.g., thousands of files).

Simply pass a .csv or .txt file list. The tool automatically switches to Batch Mode.

```Bash

# Run batch alignment
flexaligner filelist.csv --device cuda
```
ğŸ“ Batch File Format Example (filelist.csv):

```
/data/audio/001.wav                                     <-- Auto-infer text & output
/data/audio/002.wav,/data/text/002.txt                  <-- Explicit text
/data/audio/003.mp3,,/results/003_fixed.TextGrid        <-- Explicit output
```
2. Python API
Designed for seamless integration into research pipelines (e.g., slicing audio for EEG/MEG analysis).

```Python

from flexaligner import FlexAligner

# 1. Initialize (Loads model once, auto-downloads if needed)
# You can specify device="cuda" or max_gap_s here.
aligner = FlexAligner({
    "device": "cuda", 
    "lang": "zh"  # Optional: Lock language
})

# 2. Align a single file
chunks = aligner.align(
    audio_path="corpus/SP01.wav", 
    text_path="corpus/SP01.txt", 
    output_path="output/SP01.TextGrid"
)

# 3. Or align a batch list (Efficient)
tasks = [
    ("corpus/A.wav", "corpus/A.txt", "out/A.TextGrid"),
    ("corpus/B.wav", "corpus/B.txt", "out/B.TextGrid"),
]
aligner.align_batch(tasks)

print(f"âœ… Processing complete.")
```
## ğŸ—“ï¸ Roadmap

- [x] **Core Alignment Engine:** Two-stage architecture (CTC Chunking + Local Alignment).
- [x] **Multi-Lingual Support:** Pre-trained models for Mandarin & English.
- [x] **Unified Batch Inference:** Smart CLI entry point supporting `.csv` / `.txt` file lists for high-throughput corpus processing.
    - *Usage:* `flexaligner batch_list.csv --device cuda`
- [ ] **PyPI Release:** Publish the package to the Python Package Index (PyPI) to support standard installation via `pip install flexaligner`.
- [ ] **Domain Adaptation Recipe:** Provide scripts and APIs for users to fine-tune acoustic models on specific domains (e.g., dialects, children's speech, or dysarthric speech).

ğŸ‘¨â€ğŸ’» Authors & Affiliation
```
Yiming Wang (ç‹ä¸€é¸£) - University of Science and Technology of China (USTC)

Jiahong Yuan (è¢å®¶å®) - University of Science and Technology of China (USTC)
```
ğŸ“œ Citation
If you use FlexAligner in your research, please cite:

```bibtex
@misc{flexaligner2026,
  title   = {FlexAligner: Robust Speechâ€“Text Alignment via CTC Chunking and Local Cross-Entropy Alignment},
  author  = {Wang, Yiming and Yuan, Jiahong},
  year    = {2026},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{[https://github.com/USTCPhonetics/FlexAligner](https://github.com/USTCPhonetics/FlexAligner)}},
  organization = {University of Science and Technology of China}
}
```
<div align="center"><sub>Built by USTCPhonetics.</sub></div>


-----